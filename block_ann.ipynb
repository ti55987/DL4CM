{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import load\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "\n",
    "from prl_utils import (\n",
    "    Mode,\n",
    "    get_features,\n",
    "    get_labels,\n",
    "    normalize_train_labels,\n",
    "    normalize_val_labels,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-07 14:48:55.442558: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2025-02-07 14:48:55.443624: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2025-02-07 14:48:55.444383: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25, 3, 20, 16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-07 14:48:55.526313: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2025-02-07 14:48:55.527320: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2025-02-07 14:48:55.527903: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2025-02-07 14:48:55.605688: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2025-02-07 14:48:55.606509: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2025-02-07 14:48:55.607142: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25, 30)\n",
      "(25, 3, 20, 16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-07 14:48:55.999894: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2025-02-07 14:48:56.000895: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2025-02-07 14:48:56.001427: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2025-02-07 14:48:56.077221: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2025-02-07 14:48:56.078040: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2025-02-07 14:48:56.078752: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2025-02-07 14:48:56.154926: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2025-02-07 14:48:56.155942: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2025-02-07 14:48:56.156530: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25, 30)\n",
      "4/4 [==============================] - 2s 12ms/step - loss: 1.1762\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.1331\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.2727\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.4099\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.4228\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.2146\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.4835\n",
      "Epoch 8/10\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.3860\n",
      "Epoch 9/10\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.2050\n",
      "Epoch 10/10\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.6057\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import GRU, Dense, Dropout\n",
    "import numpy as np\n",
    "\n",
    "class BlockwiseGRU(tf.keras.Model):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, num_blocks):\n",
    "        \"\"\"\n",
    "        GRU model that processes time series data block-by-block.\n",
    "\n",
    "        Args:\n",
    "        - input_dim (int): Feature dimension per time step.\n",
    "        - hidden_dim (int): Hidden size of GRU.\n",
    "        - output_dim (int): Number of output variables.\n",
    "        - num_blocks (int): Number of time series blocks.\n",
    "        \"\"\"\n",
    "        super(BlockwiseGRU, self).__init__()\n",
    "        \n",
    "        self.num_blocks = num_blocks\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        # Shared GRU layer (processes one block at a time)\n",
    "        self.gru = GRU(hidden_dim, return_sequences=True, return_state=True)\n",
    "        self.gru_dropout = Dropout(0.5)\n",
    "        self.dense1 = Dense(int(hidden_dim/2), activation='relu')\n",
    "        self.dropout1 = Dropout(0.5)\n",
    "        self.dense2 = Dense(int(hidden_dim/4), activation='relu')\n",
    "        self.dropout2 = Dropout(0.5)\n",
    "        # Final output layer (fully connected)\n",
    "        self.output_layer = Dense(output_dim)\n",
    "\n",
    "    def call(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass.\n",
    "\n",
    "        Args:\n",
    "        - x (Tensor): Shape (batch_size, num_blocks, time_steps_per_block, input_dim)\n",
    "\n",
    "        Returns:\n",
    "        - output (Tensor): Shape (batch_size, output_dim)\n",
    "        \"\"\"\n",
    "        print(x.shape)\n",
    "        batch_size, num_blocks, time_steps, _ = x.shape\n",
    "\n",
    "        # Initialize hidden state (default to zeros)\n",
    "        hidden_state = tf.zeros((batch_size, self.hidden_dim))\n",
    "        b_outputs = []\n",
    "\n",
    "        for i in range(num_blocks):\n",
    "            block = x[:, i, :, :]  # Extract the i-th block: (batch_size, time_steps, input_dim)\n",
    "            _, hidden_state = self.gru(block, initial_state=hidden_state)  # Update hidden state\n",
    "            b_outputs.append(hidden_state)\n",
    "        \n",
    "        # Concatenate the outputs of the GRU layers or global average pooling\n",
    "        rnn_outputs = tf.keras.layers.Concatenate(axis=1)(b_outputs)\n",
    "        print(rnn_outputs.shape)\n",
    "        rnn_outputs = self.gru_dropout(rnn_outputs)\n",
    "        # Dense layers\n",
    "        d_outputs_2 = self.dense1(rnn_outputs)\n",
    "        d_outputs_2 = self.dropout1(d_outputs_2)\n",
    "        d_outputs_2 = self.dense2(d_outputs_2)\n",
    "        d_outputs_2 = self.dropout2(d_outputs_2)        \n",
    "        # Use the final hidden state to make a prediction\n",
    "        output = self.output_layer(d_outputs_2)\n",
    "        \n",
    "        return output\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Example Usage\n",
    "batch_size = 25\n",
    "num_blocks = 3\n",
    "time_steps_per_block = 20\n",
    "input_dim = 16\n",
    "hidden_dim = 10\n",
    "output_dim = 3\n",
    "\n",
    "# Create model\n",
    "best_model = BlockwiseGRU(input_dim, hidden_dim, output_dim, num_blocks)\n",
    "\n",
    "# Generate dummy y labels (batch_size, output_dim)\n",
    "y = np.random.randn(100, output_dim).astype(np.float32)\n",
    "\n",
    "# Generate dummy input data (100 agents, num_blocks, time_steps_per_block, input_dim)\n",
    "x = np.random.randn(100, num_blocks, time_steps_per_block, input_dim).astype(np.float32)\n",
    "\n",
    "\n",
    "# Compile Model with Custom Loss\n",
    "best_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=3e-4),\n",
    "              loss='mse')\n",
    "\n",
    "# Train the model\n",
    "history = best_model.fit(\n",
    "    x=x, \n",
    "    y=y, \n",
    "    epochs=10, \n",
    "    batch_size=batch_size)\n",
    "\n",
    "\n",
    "\n",
    "# # Forward pass\n",
    "# output = model(x)\n",
    "# print(output.shape)  # Expected: (batch_size, output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.12.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-07 14:51:23.858805: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2025-02-07 14:51:23.859591: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2025-02-07 14:51:23.860186: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3, 20, 16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-07 14:51:23.939663: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2025-02-07 14:51:23.940506: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2025-02-07 14:51:23.941125: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2025-02-07 14:51:24.022450: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2025-02-07 14:51:24.023101: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2025-02-07 14:51:24.023749: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 30)\n",
      "(2, 3, 20, 16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-07 14:51:24.381438: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2025-02-07 14:51:24.382675: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2025-02-07 14:51:24.383365: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2025-02-07 14:51:24.455244: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2025-02-07 14:51:24.455924: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2025-02-07 14:51:24.456436: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2025-02-07 14:51:24.529016: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2025-02-07 14:51:24.529573: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2025-02-07 14:51:24.530311: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 30)\n",
      "50/50 [==============================] - 2s 6ms/step - loss: 1.8918\n",
      "Epoch 2/10\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 1.2362\n",
      "Epoch 3/10\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 1.3833\n",
      "Epoch 4/10\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 1.1919\n",
      "Epoch 5/10\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 1.1068\n",
      "Epoch 6/10\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 1.0439\n",
      "Epoch 7/10\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 1.2645\n",
      "Epoch 8/10\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 1.0087\n",
      "Epoch 9/10\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 1.1570\n",
      "Epoch 10/10\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 1.2665\n"
     ]
    }
   ],
   "source": [
    "# Create model\n",
    "best_model = BlockwiseGRU(input_dim, hidden_dim, output_dim, num_blocks)\n",
    "# Generate dummy y labels (batch_size, output_dim)\n",
    "y = np.random.randn(100, output_dim).astype(np.float32)\n",
    "\n",
    "# Generate dummy input data (batch_size, num_blocks, time_steps_per_block, input_dim)\n",
    "x = np.random.randn(100, num_blocks, time_steps_per_block, input_dim).astype(np.float32)\n",
    "\n",
    "\n",
    "# Compile Model with Custom Loss\n",
    "best_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=3e-4),\n",
    "              loss='mse')\n",
    "history = best_model.fit(\n",
    "    x=x, \n",
    "    y=y, \n",
    "    epochs=10, \n",
    "    batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 3)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import GRU, Dense\n",
    "import numpy as np\n",
    "\n",
    "class ConditionAwareGRU(tf.keras.Model):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, num_blocks):\n",
    "        \"\"\"\n",
    "        GRU model with condition-based masking.\n",
    "        \n",
    "        Args:\n",
    "        - input_dim (int): Feature dimension per time step.\n",
    "        - hidden_dim (int): Hidden size of GRU.\n",
    "        - output_dim (int): Number of inferred variables (A, B, C).\n",
    "        - num_blocks (int): Number of time series blocks.\n",
    "        \"\"\"\n",
    "        super(ConditionAwareGRU, self).__init__()\n",
    "        \n",
    "        self.num_blocks = num_blocks\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        # Shared GRU layer (processes one block at a time)\n",
    "        self.gru = GRU(hidden_dim, return_sequences=True, return_state=True)\n",
    "        \n",
    "        # Separate output layers for condition-dependent and condition-agnostic variables\n",
    "        self.output_A = Dense(1)  # Variable A (Condition 1)\n",
    "        self.output_B = Dense(1)  # Variable B (Condition 2)\n",
    "        self.output_C = Dense(1)  # Variable C (Condition agnostic)\n",
    "\n",
    "    def call(self, x, conditions):\n",
    "        \"\"\"\n",
    "        Forward pass.\n",
    "        \n",
    "        Args:\n",
    "        - x (Tensor): Shape (num_agents, num_blocks, time_steps_per_block, input_dim)\n",
    "        - conditions (Tensor): Shape (num_agents, num_blocks), binary condition indicator (1 = Condition 1, 0 = Condition 2)\n",
    "\n",
    "        Returns:\n",
    "        - output (Tensor): Shape (num_agents, 3) for (A, B, C)\n",
    "        \"\"\"\n",
    "        num_agents, num_blocks, time_steps, _ = x.shape\n",
    "\n",
    "        # Initialize hidden states\n",
    "        hidden_state = tf.zeros((num_agents, self.hidden_dim))\n",
    "\n",
    "        # Store hidden states for condition-based processing\n",
    "        hidden_states_A = []  # For Variable A (Condition 1)\n",
    "        hidden_states_B = []  # For Variable B (Condition 2)\n",
    "        hidden_states_C = []  # For Variable C (Condition agnostic)\n",
    "\n",
    "        # Process each block sequentially\n",
    "        for i in range(num_blocks):\n",
    "            block = x[:, i, :, :]  # Extract i-th block (num_agents, time_steps, input_dim)\n",
    "            _, hidden_state = self.gru(block, initial_state=hidden_state)  # Update hidden state\n",
    "            \n",
    "            # Extract the condition mask\n",
    "            condition_mask = tf.expand_dims(conditions[:, i], axis=-1)  # Shape (num_agents, 1)\n",
    "\n",
    "            # Store condition-masked hidden states\n",
    "            hidden_states_A.append(hidden_state * condition_mask)      # Only update A when Condition 1\n",
    "            hidden_states_B.append(hidden_state * (1 - condition_mask)) # Only update B when Condition 2\n",
    "            hidden_states_C.append(hidden_state)                        # Always update C\n",
    "\n",
    "        # Aggregate hidden states\n",
    "        final_A = tf.reduce_sum(tf.stack(hidden_states_A, axis=1), axis=1)  # Sum over Condition 1 blocks\n",
    "        final_B = tf.reduce_sum(tf.stack(hidden_states_B, axis=1), axis=1)  # Sum over Condition 2 blocks\n",
    "        final_C = tf.reduce_mean(tf.stack(hidden_states_C, axis=1), axis=1) # Mean over all blocks\n",
    "\n",
    "        # Predict variables\n",
    "        var_A = self.output_A(final_A)  # Variable A\n",
    "        var_B = self.output_B(final_B)  # Variable B\n",
    "        var_C = self.output_C(final_C)  # Variable C\n",
    "\n",
    "        # Concatenate outputs into (num_agents, 3)\n",
    "        output = tf.concat([var_A, var_B, var_C], axis=-1)\n",
    "        \n",
    "        return output\n",
    "\n",
    "# Example Usage\n",
    "num_agents = 3\n",
    "num_blocks = 3\n",
    "time_steps_per_block = 20\n",
    "input_dim = 16\n",
    "hidden_dim = 32\n",
    "output_dim = 3  # A, B, C\n",
    "\n",
    "# Create model\n",
    "model = ConditionAwareGRU(input_dim, hidden_dim, output_dim, num_blocks)\n",
    "\n",
    "# Generate dummy input data (num_agents, num_blocks, time_steps_per_block, input_dim)\n",
    "x = np.random.randn(num_agents, num_blocks, time_steps_per_block, input_dim).astype(np.float32)\n",
    "\n",
    "# Generate random conditions (1 = Condition 1, 0 = Condition 2) for each block per agent\n",
    "conditions = np.random.randint(0, 2, size=(num_agents, num_blocks)).astype(np.float32)\n",
    "\n",
    "# Forward pass\n",
    "output = model(x, conditions)\n",
    "print(output.shape)  # Expected: (num_agents, 3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl4rl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
