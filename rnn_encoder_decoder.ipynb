{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qn1fvGqqmah3"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime\n",
        "\n",
        "from prl_utils import (\n",
        "    Mode,\n",
        "    read_hdf5,\n",
        "    get_features,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SG8cIyhgmdVG"
      },
      "outputs": [],
      "source": [
        "# @title Constants\n",
        "N_TRAIN_AGENT = 3000\n",
        "N_VAL_AGENT = 200\n",
        "NUM_TRIAL = 2000\n",
        "mode = Mode.PRL2_intractable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_latent_labels(data, num_agents, num_trial, mode):\n",
        "  if mode == Mode.PRL2_intractable:\n",
        "    return data['which_state'].to_numpy().astype(np.float32).reshape((num_agents, num_trial))\n",
        "  elif mode == Mode.PRL2:\n",
        "    return data['rpe_history'].to_numpy().astype(np.float32).reshape((num_agents, num_trial))\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Read data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oP4FPRIImrT_"
      },
      "outputs": [],
      "source": [
        "# @title Read data\n",
        "\n",
        "list_of_train_files = [\n",
        "  #'5000agent_200t_2ParamRL.csv'\n",
        "  '3000agent_2000t_2ParamRL_intractable_fixed_inattention_tau_validation.h5',\n",
        "]\n",
        "\n",
        "all_train_features = []\n",
        "train_labels = []\n",
        "num_trial = NUM_TRIAL\n",
        "for f in list_of_train_files:\n",
        "  data = read_hdf5(f) if '.h5' in f else pd.read_csv(f)\n",
        "\n",
        "  num_agents = 20000 if '20000agent' in f else N_TRAIN_AGENT\n",
        "  features = get_features(data, num_agents, num_trial, mode=mode)\n",
        "  all_train_features.append(features)\n",
        "\n",
        "  if mode == Mode.PRL2_intractable:\n",
        "    train_labels.append(data['which_state'].to_numpy().astype(np.float32).reshape((num_agents, num_trial)))\n",
        "  elif mode == Mode.PRL2:\n",
        "    train_labels.append(data['rpe_history'].to_numpy().astype(np.float32).reshape((num_agents, num_trial)))\n",
        "\n",
        "  del data # save memory\n",
        "\n",
        "all_train_features = tf.concat(all_train_features, 0)\n",
        "train_labels = tf.concat(train_labels, 0)\n",
        "\n",
        "n_agent = 500\n",
        "all_train_features = all_train_features[:n_agent, :NUM_TRIAL, :]\n",
        "train_labels = train_labels[:n_agent, :NUM_TRIAL]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A5kurGphm4-5"
      },
      "outputs": [],
      "source": [
        "from sklearn.utils import shuffle\n",
        "\n",
        "train_features, normalized_train_labels = shuffle(all_train_features.numpy(), train_labels.numpy(), random_state=0)\n",
        "if mode == Mode.PRL2_intractable:\n",
        "    normalized_train_labels = tf.keras.utils.to_categorical(normalized_train_labels, num_classes=2)\n",
        "\n",
        "print(train_features.shape, len(normalized_train_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cMcTyc3FnP_g",
        "outputId": "082ba385-f3bc-455d-d63d-60806eb7fff0"
      },
      "outputs": [],
      "source": [
        "if mode == Mode.PRL2_intractable:\n",
        "    # Pad a dummy to the front of the input\n",
        "    input_paddings = tf.constant([[1, 0], [0, 0]]) \n",
        "    decoder_input_data = tf.unstack(normalized_train_labels)\n",
        "    # Pad a dummy to the end of the output\n",
        "    output_paddings = tf.constant([[0, 1], [0, 0]])\n",
        "    decoder_target_data = tf.unstack(normalized_train_labels)\n",
        "\n",
        "    for j in range(len(normalized_train_labels)):\n",
        "        decoder_input_data[j] = tf.pad(normalized_train_labels[j], input_paddings, \"CONSTANT\", constant_values=0)\n",
        "        decoder_target_data[j] = tf.pad(normalized_train_labels[j], output_paddings, \"CONSTANT\", constant_values=0)\n",
        "\n",
        "    decoder_input_data = tf.stack(decoder_input_data)\n",
        "    decoder_target_data = tf.stack(decoder_target_data)\n",
        "else:\n",
        "    decoder_input_data = np.zeros((normalized_train_labels.shape[0], normalized_train_labels.shape[1]+1))\n",
        "    decoder_target_data = np.zeros((normalized_train_labels.shape[0], normalized_train_labels.shape[1]+1))\n",
        "    # Pad a dummy to the front of the input\n",
        "    decoder_input_data[:, 1:] = normalized_train_labels\n",
        "    # Pad a dummy to the end of the output\n",
        "    decoder_target_data[:, :normalized_train_labels.shape[1]] = normalized_train_labels\n",
        "print(decoder_input_data.shape, decoder_target_data.shape)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "dwSQTwKWQgwc"
      },
      "source": [
        "### Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GhihcV4VsqbG"
      },
      "outputs": [],
      "source": [
        "# @title Model definition\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "from tensorflow.keras.layers import (\n",
        "    Dense,\n",
        "    Dropout,\n",
        "    LSTM,\n",
        "    Bidirectional,\n",
        "    GRU,\n",
        "    Concatenate,\n",
        ")\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "\n",
        "RNN = GRU\n",
        "is_bidirection = True\n",
        "output_dim = 2 if mode == Mode.PRL2_intractable else 1\n",
        "batch_size = 128\n",
        "units = 96\n",
        "learning_rate = 3e-3\n",
        "op_loss = 'binary_crossentropy'\n",
        "decay = 0 # Learning rate decay\n",
        "\n",
        "n_agent = train_features.shape[0]\n",
        "identifier = f'{n_agent}a_ed_{NUM_TRIAL}t_{RNN.__name__}_B{batch_size}_U{units}_{learning_rate}'\n",
        "if is_bidirection:\n",
        "  identifier = 'bi_' + identifier\n",
        "\n",
        "print(identifier)\n",
        "\n",
        "# Encoder\n",
        "encoder_inputs = layers.Input(shape=(None, train_features.shape[2]))\n",
        "\n",
        "if is_bidirection:\n",
        "    encoder = Bidirectional(RNN(units, return_state=True, return_sequences=True))\n",
        "else:\n",
        "    encoder = RNN(units, return_state=True, return_sequences=True)\n",
        "\n",
        "# We discard `encoder_outputs` and only keep the states.\n",
        "if RNN.__name__ == 'GRU':\n",
        "  if is_bidirection:\n",
        "    encoder_outputs, forward_h, backward_h = encoder(encoder_inputs)\n",
        "    state_h = Concatenate()([forward_h, backward_h])\n",
        "  else:    \n",
        "    encoder_outputs, state_h = encoder(encoder_inputs)\n",
        "  \n",
        "  encoder_states = state_h\n",
        "else:\n",
        "  if is_bidirection:\n",
        "    encoder_outputs, forward_h, forward_c, backward_h, backward_c = encoder(encoder_inputs)\n",
        "    state_h = Concatenate()([forward_h, backward_h])\n",
        "    state_c = Concatenate()([forward_c, backward_c])\n",
        "  else:    \n",
        "    encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
        "  encoder_states = [state_h, state_c]\n",
        "\n",
        "# Decoder \n",
        "# Set up the decoder, using `encoder_states` as initial state.\n",
        "decoder_inputs = layers.Input(shape=(None, output_dim))\n",
        "# We set up our decoder to return full output sequences,\n",
        "# and to return internal states as well. We don't use the\n",
        "# return states in the training model, but we will use them in inference.\n",
        "decoder_units = units*2 if is_bidirection else units\n",
        "decoder_lstm = RNN(decoder_units, return_sequences=True, return_state=True)\n",
        "if RNN.__name__ == 'GRU':\n",
        "    decoder_outputs, _ = decoder_lstm(decoder_inputs,\n",
        "                                    initial_state=encoder_states)\n",
        "else:\n",
        "    decoder_outputs, _, _ = decoder_lstm(decoder_inputs,\n",
        "                                     initial_state=encoder_states)\n",
        "\n",
        "decoder_dense = Dense(output_dim, activation='softmax') #'softmax\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "# Define the model that will turn\n",
        "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
        "best_model = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tqpjcsKP1zOu",
        "outputId": "d504c8e0-734f-4944-869f-ccd22681e355"
      },
      "outputs": [],
      "source": [
        "optimiser = keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "best_model.compile(optimizer=optimiser, loss=op_loss)\n",
        "\n",
        "callbacks = [EarlyStopping(monitor='val_loss', patience=30, restore_best_weights=True)]\n",
        "history = best_model.fit([train_features, decoder_input_data], decoder_target_data,\n",
        "          batch_size=batch_size,\n",
        "          epochs=100,\n",
        "          callbacks=callbacks,\n",
        "          validation_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "result = pd.DataFrame(history.history)\n",
        "ax = sns.lineplot(result)\n",
        "ax.set_xlabel('epochs')\n",
        "ax.set_ylabel(f'{op_loss} loss')\n",
        "\n",
        "plt.savefig(f'{identifier}_loss.png')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "m6BwzUDKQcei"
      },
      "source": [
        "## Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lTOSbjTUQKN1"
      },
      "outputs": [],
      "source": [
        "test_original_num_trial = NUM_TRIAL\n",
        "\n",
        "# 3000agent_2000t_2ParamRL_intractable_fixed_inattention_tau_test\n",
        "test_data = pd.read_csv('3000agent_2000t_2ParamRL_intractable_fixed_inattention_tau_test.csv')\n",
        "\n",
        "test_features = get_features(test_data, N_VAL_AGENT, test_original_num_trial, mode=mode)\n",
        "test_labels = get_latent_labels(test_data, N_VAL_AGENT, test_original_num_trial, mode)\n",
        "\n",
        "# Process the test features and labels\n",
        "test_features = test_features[:, :NUM_TRIAL, :]\n",
        "test_labels = test_labels[:, :NUM_TRIAL]\n",
        "\n",
        "print(test_features.shape, len(test_labels))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Inference Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bPiCT3y2Q4Xg",
        "outputId": "60c0e609-1f4f-41ca-b90c-7c040d5deda3"
      },
      "outputs": [],
      "source": [
        "# @title Inference model\n",
        "latent_dim = units*2 if is_bidirection else units\n",
        "\n",
        "encoder_model = keras.Model(encoder_inputs, encoder_states)\n",
        "\n",
        "if RNN.__name__ == 'GRU':\n",
        "    decoder_state_input_h = layers.Input(shape=(latent_dim,))\n",
        "    decoder_states_inputs = [decoder_state_input_h]        \n",
        "elif RNN.__name__ == 'LSTM':\n",
        "    decoder_state_input_h = layers.Input(shape=(latent_dim,))\n",
        "    decoder_state_input_c = layers.Input(shape=(latent_dim,))\n",
        "    decoder_states_inputs =  [decoder_state_input_h, decoder_state_input_c]\n",
        "\n",
        "if RNN.__name__ == 'GRU':\n",
        "    decoder_outputs, state_h = decoder_lstm(\n",
        "        decoder_inputs, initial_state=decoder_states_inputs)\n",
        "    decoder_states = [state_h]\n",
        "else:\n",
        "    decoder_outputs, state_h, state_c = decoder_lstm(\n",
        "        decoder_inputs, initial_state=decoder_states_inputs)\n",
        "    decoder_states = [state_h, state_c]\n",
        "\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "decoder_model = keras.Model(\n",
        "    [decoder_inputs] + decoder_states_inputs,\n",
        "    [decoder_outputs] + decoder_states)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TvbQ5HDpiew4"
      },
      "outputs": [],
      "source": [
        "def decode_sequence(input_seq, num_decoder_tokens, max_decoder_seq_length: int=NUM_TRIAL):\n",
        "    # Encode the input as state vectors.\n",
        "    states_value = encoder_model.predict(input_seq)\n",
        "    # Generate first value of the decoder input sequence\n",
        "    decoder_input = np.zeros((input_seq.shape[0], 1, num_decoder_tokens))\n",
        "\n",
        "    # Sampling loop for a batch of sequences\n",
        "    # (to simplify, here we assume a batch of size 1).\n",
        "    stop_condition = False\n",
        "    decoded_sentence = []\n",
        "    while not stop_condition:\n",
        "        if RNN.__name__ == 'GRU':\n",
        "            output_tokens, h = decoder_model.predict(\n",
        "                [decoder_input] + states_value)\n",
        "        else:\n",
        "            output_tokens, h, c = decoder_model.predict(\n",
        "                [decoder_input] + states_value)\n",
        "        # Sample a token\n",
        "        predicted_state = np.argmax(output_tokens, axis=-1)\n",
        "        decoded_sentence.append(predicted_state)\n",
        "\n",
        "        # Exit condition: either hit max length\n",
        "        # or find stop character.\n",
        "        if len(decoded_sentence) == max_decoder_seq_length:\n",
        "            stop_condition = True\n",
        "\n",
        "        # Update the target sequence (of length 1).\n",
        "        #target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
        "        decoder_input = output_tokens\n",
        "\n",
        "        # Update states\n",
        "        if RNN.__name__ == 'GRU':\n",
        "            states_value = [h]\n",
        "        else:\n",
        "            states_value = [h, c]\n",
        "\n",
        "    #return decoded_sentence\n",
        "    return np.concatenate(decoded_sentence, axis=1)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "id": "5vkitvWSSd5b",
        "outputId": "a58f93c7-4246-413a-a902-07794dab82ff"
      },
      "outputs": [],
      "source": [
        "tf.debugging.enable_traceback_filtering()\n",
        "prediction = decode_sequence(test_features, num_decoder_tokens=1)\n",
        "prediction.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "agent = 12\n",
        "result = pd.DataFrame({'true_label':  test_labels[agent], 'dl_label': prediction[agent]})\n",
        "markers = {\"true_label\": \"v\", \"dl_label\": \".\"}\n",
        "#sns.scatterplot(result, markers=markers) #{\"true_label\": 10, \"dl_label\": 4\n",
        "sns.lineplot(result)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "dwSQTwKWQgwc"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "dl4rl",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
